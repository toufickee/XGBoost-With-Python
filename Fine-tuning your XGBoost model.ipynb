{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fine-tuning your XGBoost model.ipynb","provenance":[],"authorship_tag":"ABX9TyOWNzGNMw996P6K7d/AncYg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"i2TVwRe08RcD","colab_type":"text"},"source":["Tuning the number of boosting rounds"]},{"cell_type":"code","metadata":{"id":"sZCwudjk8Kyl","colab_type":"code","colab":{}},"source":["# Create the DMatrix: housing_dmatrix\n","housing_dmatrix = xgb.DMatrix(data=X,label=y)\n","\n","# Create the parameter dictionary for each tree: params \n","params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n","\n","# Create list of number of boosting rounds\n","num_rounds = [5, 10, 15]\n","\n","# Empty list to store final round rmse per XGBoost model\n","final_rmse_per_round = []\n","\n","# Iterate over num_rounds and build one model per num_boost_round parameter\n","for curr_num_rounds in num_rounds:\n","\n","    # Perform cross-validation: cv_results\n","    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=5, metrics=\"rmse\", as_pandas=True, seed=123)\n","    \n","    # Append final round RMSE\n","    final_rmse_per_round.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n","\n","# Print the resultant DataFrame\n","num_rounds_rmses = list(zip(num_rounds, final_rmse_per_round))\n","print(pd.DataFrame(num_rounds_rmses,columns=[\"num_boosting_rounds\",\"rmse\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1GTu03358YMu","colab_type":"text"},"source":["Automated boosting round selection using early_stopping"]},{"cell_type":"code","metadata":{"id":"QPsb1EvF8dmB","colab_type":"code","colab":{}},"source":["# Create your housing DMatrix: housing_dmatrix\n","housing_dmatrix = xgb.DMatrix(data=X, label=y)\n","\n","# Create the parameter dictionary for each tree: params\n","params = {\"objective\":\"reg:linear\", \"max_depth\":4}\n","\n","# Perform cross-validation with early stopping: cv_results\n","cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=3, num_boost_round=50, metrics=\"rmse\", as_pandas=True, seed=123,early_stopping_rounds=10)\n","\n","# Print cv_results\n","print(cv_results)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JfbYioDW8ioE","colab_type":"text"},"source":["Tuning eta"]},{"cell_type":"code","metadata":{"id":"I9Kn-66J8ntS","colab_type":"code","colab":{}},"source":["# Create your housing DMatrix: housing_dmatrix\n","housing_dmatrix = xgb.DMatrix(data=X, label=y)\n","\n","# Create the parameter dictionary for each tree (boosting round)\n","params = {\"objective\":\"reg:linear\", \"max_depth\":3}\n","\n","# Create list of eta values and empty list to store final round rmse per xgboost model\n","eta_vals = [0.001, 0.01, 0.1]\n","best_rmse = []\n","\n","# Systematically vary the eta \n","for curr_val in eta_vals:\n","\n","    params[\"eta\"] = curr_val\n","    \n","    # Perform cross-validation: cv_results\n","    cv_results = xgb.cv(dtrain=housing_dmatrix,params=params,nfold=3,early_stopping_rounds=5,num_boost_round=10,metrics='rmse',seed=123,as_pandas=True)\n","    \n","    \n","    \n","    # Append the final round rmse to best_rmse\n","    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n","\n","# Print the resultant DataFrame\n","print(pd.DataFrame(list(zip(eta_vals, best_rmse)), columns=[\"eta\",\"best_rmse\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mduq-EsV8rYa","colab_type":"text"},"source":["Tuning Max Depth"]},{"cell_type":"code","metadata":{"id":"YG77WeJG82Ll","colab_type":"code","colab":{}},"source":["# Create your housing DMatrix\n","housing_dmatrix = xgb.DMatrix(data=X,label=y)\n","\n","# Create the parameter dictionary\n","params = {\"objective\":\"reg:linear\"}\n","\n","# Create list of max_depth values\n","max_depths = [2,5,10,20]\n","best_rmse = []\n","\n","# Systematically vary the max_depth\n","for curr_val in max_depths:\n","\n","    params[\"max_depth\"] = curr_val\n","    \n","    # Perform cross-validation\n","    cv_results = xgb.cv(dtrain=housing_dmatrix,nfold=2,params=params,early_stopping_rounds=5,num_boost_round=10,metrics=\"rmse\",seed=123,as_pandas=True)\n","    \n","    \n","    \n","    # Append the final round rmse to best_rmse\n","    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n","\n","# Print the resultant DataFrame\n","print(pd.DataFrame(list(zip(max_depths, best_rmse)),columns=[\"max_depth\",\"best_rmse\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"shAXxV6g9AAU","colab_type":"text"},"source":["Tuning colsample_bytree"]},{"cell_type":"code","metadata":{"id":"kkIOVszb9F5L","colab_type":"code","colab":{}},"source":["# Create your housing DMatrix\n","housing_dmatrix = xgb.DMatrix(data=X,label=y)\n","\n","# Create the parameter dictionary\n","params={\"objective\":\"reg:linear\",\"max_depth\":3}\n","\n","# Create list of hyperparameter values: colsample_bytree_vals\n","colsample_bytree_vals= [0.1,0.5,0.8,1]\n","best_rmse = []\n","\n","# Systematically vary the hyperparameter value \n","for curr_val in colsample_bytree_vals:\n","\n","    params[\"colsample_bytree\"] = curr_val\n","    \n","    # Perform cross-validation\n","    cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2,\n","                 num_boost_round=10, early_stopping_rounds=5,\n","                 metrics=\"rmse\", as_pandas=True, seed=123)\n","    \n","    # Append the final round rmse to best_rmse\n","    best_rmse.append(cv_results[\"test-rmse-mean\"].tail().values[-1])\n","\n","# Print the resultant DataFrame\n","print(pd.DataFrame(list(zip(colsample_bytree_vals, best_rmse)), columns=[\"colsample_bytree\",\"best_rmse\"]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_vaydTuw9Hal","colab_type":"text"},"source":["Grid search with XGBoost"]},{"cell_type":"code","metadata":{"id":"qzP4gvnq9M7L","colab_type":"code","colab":{}},"source":["# Create the parameter grid: gbm_param_grid\n","gbm_param_grid = {\n","    'colsample_bytree': [0.3, 0.7],\n","    'n_estimators': [50],\n","    'max_depth': [2, 5]\n","}\n","\n","# Instantiate the regressor: gbm\n","gbm = xgb.XGBRegressor()\n","\n","# Perform grid search: grid_mse\n","grid_mse = GridSearchCV(param_grid=gbm_param_grid,estimator=gbm,scoring=\"neg_mean_squared_error\",cv=4,verbose=1)\n","\n","\n","# Fit grid_mse to the data\n","grid_mse.fit(X,y)\n","\n","# Print the best parameters and lowest RMSE\n","print(\"Best parameters found: \", grid_mse.best_params_)\n","print(\"Lowest RMSE found: \", np.sqrt(np.abs(grid_mse.best_score_)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_R6nG-Cy9P0u","colab_type":"text"},"source":["Random S"]}]}