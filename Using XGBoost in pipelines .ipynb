{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Using XGBoost in pipelines .ipynb","provenance":[],"authorship_tag":"ABX9TyPWrsDNASESuuaGYReYPoR9"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"w2yP9peU9psb","colab_type":"text"},"source":["Encoding categorical columns I: LabelEncoder"]},{"cell_type":"code","metadata":{"id":"gMzTG1U79jBs","colab_type":"code","colab":{}},"source":["# Import LabelEncoder\n","from sklearn.preprocessing import LabelEncoder\n","\n","# Fill missing values with 0\n","df.LotFrontage = df.LotFrontage.fillna(0)\n","\n","# Create a boolean mask for categorical columns\n","categorical_mask = (df.dtypes == object)\n","\n","# Get list of categorical column names\n","categorical_columns = df.columns[categorical_mask].tolist()\n","\n","# Print the head of the categorical columns\n","print(df[categorical_columns].head())\n","\n","# Create LabelEncoder object: le\n","le = LabelEncoder()\n","\n","# Apply LabelEncoder to categorical columns\n","df[categorical_columns] = df[categorical_columns].apply(lambda x: le.fit_transform(x))\n","\n","# Print the head of the LabelEncoded categorical columns\n","print(df[categorical_columns].head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dz4KkEb99tIi","colab_type":"text"},"source":["Encoding categorical columns II: OneHotEncoder"]},{"cell_type":"code","metadata":{"id":"tth-33-G9x5q","colab_type":"code","colab":{}},"source":["# Import OneHotEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","# Create OneHotEncoder: ohe\n","ohe = OneHotEncoder(categorical_features=categorical_mask,sparse=False)\n","\n","# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded\n","df_encoded = ohe.fit_transform(df)\n","\n","# Print first 5 rows of the resulting dataset - again, this will no longer be a pandas dataframe\n","print(df_encoded[:5, :])\n","\n","# Print the shape of the original DataFrame\n","print(df.shape)\n","\n","# Print the shape of the transformed array\n","print(df_encoded.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cTXO_1ZM90O6","colab_type":"text"},"source":["Encoding categorical columns III: DictVectorizer"]},{"cell_type":"code","metadata":{"id":"FNujX3-x94XK","colab_type":"code","colab":{}},"source":["# Import DictVectorizer\n","from sklearn.feature_extraction import DictVectorizer\n","\n","# Convert df into a dictionary: df_dict\n","df_dict = df.to_dict(\"records\")\n","\n","# Create the DictVectorizer object: dv\n","dv = DictVectorizer(sparse=False)\n","\n","# Apply dv on df: df_encoded\n","df_encoded = dv.fit_transform(df_dict)\n","\n","# Print the resulting first five rows\n","print(df_encoded[:5,:])\n","\n","# Print the vocabulary\n","print(dv.vocabulary_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KbvrfouB9_VB","colab_type":"text"},"source":["Preprocessing within a pipeline"]},{"cell_type":"code","metadata":{"id":"imfEhwC7-A8T","colab_type":"code","colab":{}},"source":["# Import necessary modules\n","from sklearn.feature_extraction import DictVectorizer\n","from sklearn.pipeline import Pipeline\n","\n","# Fill LotFrontage missing values with 0\n","X.LotFrontage = X.LotFrontage.fillna(0)\n","\n","# Setup the pipeline steps: steps\n","steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n","         (\"xgb_model\", xgb.XGBRegressor())]\n","\n","# Create the pipeline: xgb_pipeline\n","xgb_pipeline = Pipeline(steps)\n","\n","# Fit the pipeline\n","#X=X.to_dict(\"records\")\n","df_encoded = xgb_pipeline.fit(X.to_dict(\"records\"),y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zm-h0KPe-GJK","colab_type":"text"},"source":["Cross-validating your XGBoost model"]},{"cell_type":"code","metadata":{"id":"SjtkUw2r-K7T","colab_type":"code","colab":{}},"source":["# Import necessary modules\n","from sklearn.feature_extraction import DictVectorizer\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_val_score\n","\n","# Fill LotFrontage missing values with 0\n","X.LotFrontage = X.LotFrontage.fillna(0)\n","\n","# Setup the pipeline steps: steps\n","steps = [(\"ohe_onestep\", DictVectorizer(sparse=False)),\n","         (\"xgb_model\", xgb.XGBRegressor(max_depth=2, objective=\"reg:linear\"))]\n","\n","# Create the pipeline: xgb_pipeline\n","xgb_pipeline = Pipeline(steps)\n","\n","# Cross-validate the model\n","cross_val_scores = cross_val_score(xgb_pipeline,X.to_dict(\"records\"),y,scoring=\"neg_mean_squared_error\",cv=10)\n","\n","# Print the 10-fold RMSE\n","print(\"10-fold RMSE: \", np.mean(np.sqrt(np.abs(cross_val_scores))))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ca7gYhuz-NZf","colab_type":"text"},"source":["Kidney disease case study I: Categorical Imputer"]},{"cell_type":"code","metadata":{"id":"nYkZSTxx-S8K","colab_type":"code","colab":{}},"source":["# Import necessary modules\n","from sklearn_pandas import DataFrameMapper\n","from sklearn_pandas import CategoricalImputer\n","\n","# Check number of nulls in each feature column\n","nulls_per_column = X.isnull().sum()\n","print(nulls_per_column)\n","\n","# Create a boolean mask for categorical columns\n","categorical_feature_mask = X.dtypes == object\n","\n","# Get list of categorical column names\n","categorical_columns = X.columns[categorical_feature_mask].tolist()\n","\n","# Get list of non-categorical column names\n","non_categorical_columns = X.columns[~categorical_feature_mask].tolist()\n","\n","# Apply numeric imputer\n","numeric_imputation_mapper = DataFrameMapper(\n","                                            [([numeric_feature], Imputer(strategy=\"median\")) for numeric_feature in non_categorical_columns],\n","                                            input_df=True,\n","                                            df_out=True\n","                                           )\n","\n","# Apply categorical imputer\n","categorical_imputation_mapper = DataFrameMapper(\n","                                                [(category_feature, CategoricalImputer()) for category_feature in categorical_columns],\n","                                                input_df=True,\n","                                                df_out=True\n","                                               )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bHomAeRq-WTy","colab_type":"text"},"source":["Kidney disease case study II: Feature Union"]},{"cell_type":"code","metadata":{"id":"Q92WjmTc-VzH","colab_type":"code","colab":{}},"source":["# Import FeatureUnion\n","from sklearn.pipeline import FeatureUnion\n","\n","# Combine the numeric and categorical transformations\n","numeric_categorical_union = FeatureUnion([\n","                                          (\"num_mapper\", numeric_imputation_mapper),\n","                                          (\"cat_mapper\", categorical_imputation_mapper)\n","                                         ])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rG70kR2Z-suv","colab_type":"text"},"source":["Kidney disease case study III:Full pipeline\n","\n","\n","Create the pipeline using the numeric_categorical_union, Dictifier(), and DictVectorizer(sort=False) transforms, and xgb.XGBClassifier() estimator with max_depth=3. Name the transforms \"featureunion\", \"dictifier\" \"vectorizer\", and the estimator \"clf\".\n","Perform 3-fold cross-validation on the pipeline using cross_val_score(). Pass it the pipeline, pipeline, the features, kidney_data, the outcomes, y. Also set scoring to \"roc_auc\" and cv to 3."]},{"cell_type":"code","metadata":{"id":"iL5Adtge-2KG","colab_type":"code","colab":{}},"source":["# Create full pipeline\n","pipeline = ____([\n","                     (\"____\", ____),\n","                     (\"____\", ____),\n","                     (\"____\", ____),\n","                     (\"____\", ____)\n","                    ])\n","\n","# Perform cross-validation\n","cross_val_scores = ____(____, ____, ____, ____=\"____\", ____=____)\n","\n","# Print avg. AUC\n","print(\"3-fold AUC: \", np.mean(cross_val_scores))"],"execution_count":null,"outputs":[]}]}